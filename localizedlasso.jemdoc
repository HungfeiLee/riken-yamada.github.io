# jemdoc: menu{MENU}{smis.html},showsource = LocalizedLasso,addcss{jemdoc.css}
\n
= Localized Lasso

== Introduction
The localized Lasso, which is suited for learning models that both are interpretable and have a high predictive power in problems with high dimensionality $d$ and small sample size $n$.  More specifically, we consider a function defined by local sparse models, one at each data point. We introduce sample-wise network regularization to borrow strength across the models, and sample-wise exclusive group sparsity (a.k.a., $\ell_{1,2}$ norm) to introduce diversity into the choice of feature sets in the local models. The local models are interpretable in terms of similarity of their sparsity patterns. The cost function is convex, and thus has a globally optimal solution. Moreover, we propose a simple yet efficient iterative least-squares based optimization procedure for the localized Lasso, which does not need a tuning parameter, and is guaranteed to converge to a globally optimal solution. 

== Main Idea
The localized Lasso is given as the following form
~~~
$\min_{\mathbf W} \hspace{0.1cm} \sum_{i = 1}^n (y_i - {\mathbf w}_i^\top {\mathbf x}_i)^2 + \lambda_1 \sum_{i,j = 1}^{n} r_{ij} \|{\mathbf w}_i - {\mathbf w}_j\|_{2} + \lambda_2 \sum_{i = 1}^{n}\|{\mathbf w}_i\|_1^2.$
~~~

where $r_{ij} \geq 0, r_{ij} = r_{ji}, r_{ii} = 0$ is the pre-defined Graph information.


== Features
- Can select nonlinearly related features.
- Highly scalable w.r.t. the number of features.
- Convex optimization.


== Download 
- [software/localizedlasso_matlab.zip Localized Lasso (Matlab)]#  \n
- [software/pyLocalizedLasso.zip Localized Lasso (Python)]
  #If you want to have the not well organized version of LSOM, please feel free to e-mail me. \n
  #($\textnormal{yamada@sg.cs.titech.ac.jp}$).



#== Photo Album Summarization
#- Color image
#~~~
#{}{img_left}{FIG/image_grid.png}{PAS1}{400}{300}
#~~~

#== License
#~~~
#Copyright (c) 2010 Makoto Yamada
#
# Permission is hereby granted, free of charge, to any person
# obtaining a copy of this software and associated documentation
# files (the "Software"), to deal in the Software without
# restriction, including without limitation the rights to use,
# copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the
# Software is furnished to do so, subject to the following
# conditions:
#
# The above copyright notice and this permission notice shall be
# included in all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES
# OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
# HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
# WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
# OTHER DEALINGS IN THE SOFTWARE.
#~~~

== Contact
I am happy to have any kind of feedbacks. E-mail: $\textnormal{makoto.m.yamada@ieee.org}$

== Reference
- *Yamada, M.*, [http://www.kecl.ntt.co.jp/icl/ls/members/koh/ Takeuchi, K.], [http://www.kecl.ntt.co.jp/as/members/iwata/ Iwata, T.], [http://www0.cs.ucl.ac.uk/staff/J.Shawe-Taylor/ Taylor, J-S], & [https://users.ics.aalto.fi/sami/ Kaski, S.]\n
Localized Lasso for High-Dimensional Regression. \n
In Proceedings of the [http://www.aistats.org/ International Conference on Artificial Intelligence and Statistics (AISTATS2017)]. to appear.

